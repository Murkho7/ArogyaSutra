<h2 align="center">ArogyaSutra: A Multi-Agent Framework for Multimodal Medical Reasoning in
Indic Languages
</h2>

<p align="center">
  <img src="https://github.com/user-attachments/assets/2f7995eb-65b6-4c36-9af5-848ce3cb2d4d"
       alt="AragyaSutra"
       width="300" />
</p>
<p align="center">
  ðŸ“ƒ <a href="#"><b>Paper@</b></a> |
  ðŸ¤— <a href="https://huggingface.co/collections/iit-patna-cse-ai/arogyasutra"><b>Models & Datasets Repo*</b></a>
</p>

<p align="center">
  <b>
  *A Preview of our dataset is given at Hugging Face. click on "Models & Datasets Repo" <br/>
  @ Paper and code will be uploaded Soon.
</b>
</p>

<p align="left">

Existing MLLMs, predominantly trained on English-centric data, struggle to support such use cases, limiting equitable access to AI-driven healthcare assistance. To address this challenge, we construct a large-scale multilingual multimodal medical questionâ€“answer dataset from eight heterogeneous sources, covering 31 body systems, six imaging modalities, and 21 clinical domains across English and seven major Indian languages.We further propose ArogyaSutra, an actorâ€“criticâ€“based multi-agent framework that combines tool grounding with dual-memory mechanisms to support stepwise, reasoning-aware decision making while explicitly retaining past mistakes to prevent their repeated occurrence.
<p align="left">
